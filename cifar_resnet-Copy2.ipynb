{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "# import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from adastab import AdaStab\n",
    "from OurAdam import Adam\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_train)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifartest():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = Variable(inputs, volatile=True),Variable(targets, volatile=True)\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss\n",
    "        print('test loss:{}'.format(test_loss/(batch_idx+1)))\n",
    "    \n",
    "        return test_loss/(batch_idx+1)\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += targets.size(0)\n",
    "#             correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "# % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "#     print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#         100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifartrain():\n",
    "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "        \n",
    "        print('epoch{}, loss{}'.format(epoch, running_loss/(i+1)))\n",
    "        LOSS[0, epoch] = running_loss/(i+1)\n",
    "        # Test every epoch\n",
    "#         Test_LOSS[0, epoch] = cifartest()\n",
    "    \n",
    "    print('Finished Training')\n",
    "    return LOSS, Test_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch=10\n",
    "# No test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.3046\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.8326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.5857\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.3919\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2294\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1249\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  7.9192\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  5.5913\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.5502\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.2193\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 1e-4\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = Adam(net.parameters(), lr=learning_rate, amsgrad=True)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.3076\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.8287\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.5878\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4015\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2406\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1469\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  8.7371\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  5.8922\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.8094\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.5026\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 1e-4\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.2428\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.7620\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.5445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.3902\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2710\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1789\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      " 0.1176\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9cf398f49a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mTest_LOSS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaStab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTest_LOSS\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcifartrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-c74a414192ed>\u001b[0m in \u001b[0;36mcifartrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learning_rate = 2e-4\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.4029\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.9445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.6808\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4496\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2414\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1107\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  5.4651\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  2.0704\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.0029\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  5.3445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-5\n",
    "net = ResNet18()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = np.zeros([1, max_epoch])\n",
    "Test_LOSS = np.zeros([1, max_epoch])\n",
    "optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.4180\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.9620\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.7088\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4722\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2631\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 4.5e-5\n",
    "net = ResNet18()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = np.zeros([1, max_epoch])\n",
    "Test_LOSS = np.zeros([1, max_epoch])\n",
    "optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-041f40ea43b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.5e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLOSS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/software/anaconda/3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "learning_rate = 5.5e-5\n",
    "net = ResNet18()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = np.zeros([1, max_epoch])\n",
    "Test_LOSS = np.zeros([1, max_epoch])\n",
    "optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.4272\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.9663\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.7138\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4739\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2490\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1150\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.8163\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  2.0575\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.1233\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  7.1158\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 4e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.4754\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 1.0409\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.7909\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.5584\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.3276\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  7.1845\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.3324\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.7945\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.2521\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 3e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.5854\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 1.1488\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.9121\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.7013\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.4907\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.2942\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      " 0.1572\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  8.2101\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.6960\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.0611\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 2e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.7381\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 1.3330\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 1.1490\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.9966\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.8514\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.7050\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      " 0.5614\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      " 0.4243\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      " 0.3040\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      " 0.2129\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 1e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.3435\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.8900\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.6361\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4118\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2256\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1161\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  6.1499\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.3774\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  2.0984\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.0549\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 7e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.3353\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.8742\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.6221\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4244\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2466\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1343\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  7.5438\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.7753\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.9872\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.8005\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 8e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.3089\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.8483\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.6075\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4072\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2495\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1375\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  8.1489\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.4421\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  3.7801\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.0391\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 9e-5\n",
    "# net = ResNet18()\n",
    "# net = net.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# LOSS = np.zeros([1, max_epoch])\n",
    "# Test_LOSS = np.zeros([1, max_epoch])\n",
    "# optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "# LOSS, Test_LOSS= cifartrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, lossVariable containing:\n",
      " 1.4014\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch1, lossVariable containing:\n",
      " 0.9537\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch2, lossVariable containing:\n",
      " 0.6981\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch3, lossVariable containing:\n",
      " 0.4638\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch4, lossVariable containing:\n",
      " 0.2535\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch5, lossVariable containing:\n",
      " 0.1200\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch6, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  5.8117\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch7, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  2.7171\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch8, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.3160\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch9, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  7.2454\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch10, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  5.1669\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch11, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  3.3785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch12, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  2.5072\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch13, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  2.0907\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch14, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.9735\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch15, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.6209\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch16, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.3987\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch17, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.2978\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch18, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.2276\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch19, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.0642\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch20, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  9.7206\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch21, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  9.0326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch22, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  8.4936\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch23, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  8.2790\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch24, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  7.3952\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch25, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  6.9380\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch26, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  6.3582\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch27, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  6.0471\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch28, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  5.9964\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch29, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  5.5040\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch30, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  5.0695\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch31, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  4.8408\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch32, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  4.4502\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch33, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  4.6416\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch34, lossVariable containing:\n",
      " 0.3732\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch35, lossVariable containing:\n",
      " 0.2693\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch36, lossVariable containing:\n",
      " 0.1326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch37, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  7.7009\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch38, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  4.9274\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch39, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  2.7214\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch40, lossVariable containing:\n",
      "1.00000e-02 *\n",
      "  1.5268\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch41, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  5.9124\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch42, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  2.3605\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch43, lossVariable containing:\n",
      "1.00000e-03 *\n",
      "  1.4301\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch44, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  9.4456\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch45, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  9.0994\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch46, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  6.2882\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch47, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  5.6300\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch48, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  5.1669\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch49, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  4.6726\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch50, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  4.1199\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch51, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  3.8062\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch52, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  3.4621\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch53, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  3.3625\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch54, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  3.1138\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch55, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.9076\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch56, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.9052\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch57, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.8651\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch58, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.3970\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch59, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.4852\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch60, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.2911\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch61, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.3135\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch62, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.3813\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch63, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.2916\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch64, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  2.2214\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch65, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.9216\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch66, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.7679\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch67, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.9716\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch68, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.8794\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch69, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.8124\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch70, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.7040\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch71, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.6206\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch72, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.5822\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch73, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.5917\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch74, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.4480\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch75, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.4477\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch76, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.3772\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch77, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.3765\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch78, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.3278\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch79, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.2969\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch80, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.2699\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch81, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.2604\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch82, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.2283\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch83, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.1464\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch84, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.1642\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch85, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.1340\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch86, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.3785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch87, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.1419\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch88, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.1136\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch89, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.0506\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch90, lossVariable containing:\n",
      "1.00000e-04 *\n",
      "  1.0485\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch91, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.7883\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch92, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.6375\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch93, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.9747\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch94, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.6397\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch95, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.1111\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch96, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.1829\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch97, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  9.3026\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch98, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  8.7301\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "epoch99, lossVariable containing:\n",
      "1.00000e-05 *\n",
      "  8.4618\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-5\n",
    "net = ResNet18()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = np.zeros([1, max_epoch])\n",
    "Test_LOSS = np.zeros([1, max_epoch])\n",
    "optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "LOSS, Test_LOSS= cifartrain()\n",
    "sio.savemat('nosadam_res.mat',{'loss':LOSS})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainepoch30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "net = ResNet18()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = np.zeros([1, max_epoch])\n",
    "Test_LOSS = np.zeros([1, max_epoch])\n",
    "optimizer = AdaStab(net.parameters(), lr=learning_rate, gamma=0.05)\n",
    "LOSS, Test_LOSS= cifartrain()\n",
    "sio.savemat('nosadam_res1.mat',{'loss':LOSS})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
